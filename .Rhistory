if(j == 1){
rt_sum = participant_paths$react_time[index]
}
else{
rt_sum = rt_sum + participant_paths$react_time[index]
}
cumul_rt[index] = rt_sum
trials[index] = j
cumul_rt_mean[index] = rt_sum/j
}
}
participant_paths$cumul_rt <- cumul_rt/1000
participant_paths$cumul_rt_mean <- cumul_rt_mean/1000
participant_paths$trials <- trials
#participant_acc_over_time <- ggplot(participant_paths, aes(x=trials, y=cumul_acc_mean, color = p_id))+
#  geom_hline(yintercept = acc_mean, color="#c0c0c0")
participant_rt_over_time <- ggplot(participant_paths, aes(x=trials, y=cumul_rt_mean))+
geom_smooth(color='black', size=3)+
geom_line(mapping=aes(color=p_id))+
scale_y_continuous(name = "Mean reaction time (sec)", n.breaks = 6) +
scale_x_continuous(name = "Number of trials", n.breaks = 20) +
theme(panel.grid.major.x = element_line(size = 0.001),legend.position = 0, axis.text.y = element_text(angle=0))+
coord_cartesian(ylim=c(0.4,1.5))
#for(p in keys(p_dfs)){
#  pp <- p_dfs[[p]]
#  participant_acc_over_time <- participant_acc_over_time +
#    geom_line(pp, mapping=aes(x=trials, y=cumul_acc_mean, color=p_id))
#  participant_rt_over_time <- participant_rt_over_time +
#    geom_line(pp, mapping=aes(x=trials, y=cumul_rt_mean, color=p_id))
#}
#participant_acc_over_time <- participant_acc_over_time +
#  scale_y_continuous(name = "Mean accuracy", n.breaks = 5, labels = scales::percent) +
#  scale_x_continuous(name="Number of trials",n.breaks=10)+
#  theme(legend.position = 0, axis.text.y = element_text(angle=0), panel.grid.major.x = element_line(size = 0.001)) +
#  coord_cartesian(ylim=c(0.55,1))
#grid.arrange(participant_acc_over_time, participant_rt_over_time)
participant_rt_over_time
participant_means <- exp_results %>%
group_by(p_id) %>%
summarize(mean_rt = mean(react_time), mean_acc = mean(accuracy))
summary(participant_means[c('p_id', 'mean_rt', 'mean_acc')])
m <- mean(participant_means$mean_acc)
acc_by_participant <- ggplot(participant_means,
aes(x=reorder(p_id, desc(-mean_acc)), y=mean_acc,desc()))+
geom_point() +
xlab("Participant number") +
scale_y_continuous("Mean Accuracy", labels = scales::percent, n.breaks = 8)+
geom_hline(yintercept = m, color="#c0c0c0")+
annotate("text", x='2', y=m+0.005, label=paste(round(m, 3)*100,"%"), color="#c0c0c0")+
theme(panel.grid.major.x = element_line(colour="#f4f0ec"), axis.text.y = element_text(angle=0))
acc_distribution <- ggplot(participant_means, aes(x=mean_acc))+
geom_histogram(bins=4)+
scale_x_continuous(name = "Mean Accuracy", n.breaks = 5,labels=scales::percent)+
theme(axis.title.y = element_blank(), axis.text.y = element_blank(), axis.ticks.y = element_blank())+
geom_vline(xintercept=acc_mean)
grid.arrange(acc_by_participant, acc_distribution, nrow=1, widths=c(5.5,1.5))
acc_by_participant
low_acc_participants <- participant_means %>%
filter(mean_acc < 0.85) %>%
select(p_id)
low_acc_participants <- as.numeric(as.list(low_acc_participants$p_id))
low_acc_results <- exp_results %>%
filter(as.numeric(p_id) %in% unlist(low_acc_participants)) %>%
mutate(p_id = as.factor(as.numeric(p_id)))
low_acc_boxplot <- ggplot(low_acc_results, aes(x=react_time/1000, y=lvl))+
geom_boxplot() +
facet_wrap(low_acc_results$p_id, nrow=4) +
theme(axis.text.y = element_text(angle=0),
axis.title.y = element_blank()) +
labs(caption = "Fig.4. Box plots for reaction times of low accuracy participants.")+
xlab("Reaction Time (seconds)")+
scale_x_continuous(n.breaks = 10)
low_acc_boxplot
low_acc_participants <- participant_means %>%
filter(mean_acc < 1) %>%
select(p_id)
low_acc_participants <- as.numeric(as.list(low_acc_participants$p_id))
low_acc_results <- exp_results %>%
filter(as.numeric(p_id) %in% unlist(low_acc_participants)) %>%
mutate(p_id = as.factor(as.numeric(p_id)))
low_acc_boxplot <- ggplot(low_acc_results, aes(x=react_time/1000, y=lvl))+
geom_boxplot() +
facet_wrap(low_acc_results$p_id, nrow=4) +
theme(axis.text.y = element_text(angle=0),
axis.title.y = element_blank()) +
labs(caption = "Fig.4. Box plots for reaction times of low accuracy participants.")+
xlab("Reaction Time (seconds)")+
scale_x_continuous(n.breaks = 10)
low_acc_boxplot
participant_paths <- exp_results[c("p_id", "accuracy", "react_time")]
acceptable_num_mistakes <- 0.15*stim_num
cumul_err<- c(1:rows*0)
cumul_rt <- c(1:rows*0)
for(i in 0:(p_num-1)){
err_sum = 0
rt_sum = 0
for(j in (i*stim_num):((i*stim_num)+(stim_num-1))){
err_sum <- abs(participant_paths$accuracy[j+1]-1)+err_sum
rt_sum <- participant_paths$react_time[j+1]+rt_sum
cumul_err[j+1] <- err_sum
cumul_rt[j+1] <- rt_sum
}
}
#accumulated error count
participant_paths$cumul_err <- cumul_err#/stim_num
#saved as number in minutes
participant_paths$cumul_rt <- cumul_rt/(1000*60)
#creation of df per participant
p_dfs <- hash()
for(i in 1:p_num){
p_dfs[[paste("p",i, sep="")]] <- filter(participant_paths, p_id==i)
}
#This could have been combined with the previous loop, but this way some paths could be selectively ignored when creating the plot
participant_mistake_over_time <- ggplot(participant_paths, aes(x=cumul_rt,
y=cumul_err))
for(p in keys(p_dfs)){
pp <- p_dfs[[p]]
lab_x = pp$cumul_rt[length(pp$cumul_rt)]
lab_y = pp$cumul_err[length(pp$cumul_err)]
participant_mistake_over_time <- participant_mistake_over_time +
geom_line(pp, mapping=aes(x=cumul_rt, y=cumul_err, color=p_id)) +
annotate(geom = "text", x = lab_x, y = lab_y, label=p, size=3)
}
participant_mistake_over_time <- participant_mistake_over_time +
scale_x_continuous(name = "Real Time (minutes)", n.breaks = 10) +
theme(panel.grid.major.x = element_line(size = 0.001),
legend.position = 0, axis.text.y = element_text(angle = 0))
#scale_y_continuous(name = "Error rate", n.breaks =9, labels=scales::percent) +
participant_mistake_over_time
#grid.arrange(participant_mistake_over_time, participant_acc_over_time, heights=c(5,1.5))
ppaths <- exp_results[c("p_id", "accuracy")]
ppaths$mistake <- abs(ppaths$accuracy-1)
acceptable_num_mistakes <- 0.15*stim_num
trials <- c(1:rows*0)
cumul_err<- c(1:rows*0)
for(i in 0:(p_num-1)){
err_sum <- 0
for(j in 1:stim_num){
index = (i*stim_num)+j
if(j == 1){
err_sum = ppaths$mistake[index]
}
else{
err_sum = err_sum + ppaths$mistake[index]
}
cumul_err[index] = err_sum
trials[index] = j
}
}
ppaths$cumul_err <- cumul_err
ppaths$trials <- trials
ppaths_to90 <- ppaths %>%
filter(trials < 101)
ppaths_after90to330 <- ppaths %>%
filter(trials > 100 & trials < 331)
ppaths_after330 <- ppaths %>%
filter(trials > 330)
#This could have been combined with the previous loop, but this way some paths could be selectively ignored when creating the plot
participant_mistake_over_time_alt <- ggplot(ppaths, aes(x=trials, y=cumul_err))+
geom_smooth(color='black', size=3)+
geom_smooth(data=ppaths_to90, mapping=aes(x=trials, y=cumul_err), method = 'lm', color='red')+
geom_smooth(data=ppaths_after330, mapping=aes(x=trials, y=cumul_err), method = 'lm', color='red')+
geom_smooth(data=ppaths_after90to330, mapping=aes(x=trials, y=cumul_err), method = 'lm', color='green')+
geom_hline(yintercept = acceptable_num_mistakes, color='lightgray')+
geom_line(mapping = aes(color=p_id))+
ylab("Count of mistakes")+
scale_x_continuous(name = "Number of trials", n.breaks = 10) +
theme(panel.grid.major.x = element_line(size = 0.001),
legend.position = 0,
axis.text.y = element_text(angle = 0))
participant_mistake_over_time_noY <- participant_mistake_over_time +
theme(axis.title.y = element_blank(),
axis.text.y =  element_blank(),
axis.ticks.y = element_blank())
#grid.arrange(grid.arrange(participant_mistake_over_time_alt, participant_mistake_over_time_noY, widths=c(1,1)),participant_rt_over_time, heights=c(2,1))
grid.arrange(participant_mistake_over_time_alt, participant_mistake_over_time_noY, widths=c(1,1))
stimOV <- exp_results %>%
mutate(stim_index = index%%stim_num) %>%
group_by(stim_index,stimulus,accuracy) %>%
tally()
mistake_overview <- ggplot(data=stimOV, aes(x=reorder(stimulus, desc(-accuracy)), y=n, fill=as.factor(accuracy))) +
geom_col(position = "fill", width =1) +
scale_y_continuous(labels = scales::percent) +
theme(axis.text.x = element_blank(),
axis.ticks.x = element_blank(),
legend.position = 0)+
xlab("All stimuli") +
ylab("Ratio")
stimOV2 <- exp_results %>%
group_by(stimulus) %>%
summarise(accuracy = mean(accuracy))
mistake_overview2 <- ggplot(data=stimOV2, aes(x=accuracy)) +
geom_histogram(bins=9) +
scale_x_continuous(labels = scales::percent) +
xlab("Accuracy")+
ylab("Count")+
labs(fill="Accuracy")
grid.arrange(mistake_overview, mistake_overview2, widths=c(5,2))
mistake_by_stim <- exp_results %>%
group_by(stimulus, lvl) %>%
summarise(error = (1-mean(accuracy))) %>%
filter(error>0.5)
m_by_stim_plot <- ggplot(mistake_by_stim, aes(x=error, y=reorder(stimulus, desc(-error)), fill=lvl)) +
geom_col() +
theme(axis.text.y = element_text(angle=0),
axis.title.y = element_blank(),
panel.grid.major.x = element_line(size=0.5),
panel.grid.minor = element_line(size=0.02, colour = "#c0c0c0")) +
scale_x_continuous(labels=scales::percent) +
labs(caption="Fig.7. High error Stimuli.", fill="Category \nlevel") +
xlab("Percentage of mistakes over all participants")
m_by_stim_plot
mistake_by_img <- exp_results %>%
group_by(img) %>%
summarise(error = (1-mean(accuracy)))%>%
filter(error>0.15)
m_by_img_plot <- ggplot(mistake_by_img, aes(x=error, y=reorder(img, desc(-error)))) +
geom_col() +
theme(axis.text.y = element_text(angle=0),
axis.title.y = element_blank(),
panel.grid.major.x = element_line(size=0.5),
panel.grid.minor = element_line(size=0.02, colour = "#c0c0c0")) +
scale_x_continuous(labels=scales::percent) +
labs(caption="Fig.8. High error Images.") +
xlab("Percentage of mistakes over all participants")
m_by_img_plot
mistake_by_name <- exp_results %>%
group_by(c_name, lvl) %>%
summarise(error = (1-mean(accuracy)))%>%
filter(error>0.15)
m_by_name_plot <- ggplot(mistake_by_name, aes(x=error, y=reorder(c_name, desc(-error))), group=lvl) +
geom_col(aes(fill=lvl)) +
theme(axis.text.y = element_text(angle=0),
axis.title.y = element_blank(),
panel.grid.major.x = element_line(size=0.5),
panel.grid.minor = element_line(size=0.02, colour = "#c0c0c0"),
legend.position = 0) +
scale_x_continuous(labels=scales::percent) +
labs(caption="Fig.9. High error Category names. Colors highlight the category level.") +
xlab("Percentage of mistakes over all participants")
m_by_name_plot
mistake_by_branch <- exp_results %>%
group_by(branch, lvl) %>%
summarise(error = (1-mean(accuracy)))
m_by_branch_plot <- ggplot(mistake_by_branch, aes(x=error, y=reorder(branch, desc(-error))), group=lvl) +
geom_col(aes(fill=lvl)) +
theme(axis.text.y = element_text(angle=0),
axis.title.y = element_blank(),
panel.grid.major.x = element_line(size=0.5),
panel.grid.minor = element_line(size=0.02, colour = "#c0c0c0")) +
scale_x_continuous(labels=scales::percent) +
labs(caption="Fig.10. Error rates of individual branches.", fill="Category\nLevel") +
xlab("Percentage of mistakes over all participants") +
facet_wrap(mistake_by_branch$lvl)
m_by_branch_plot
mistake_by_lvl <- exp_results %>%
group_by(lvl, stim_type) %>%
summarise(error = (1-mean(accuracy)))
m_by_lvl_plot <- ggplot(mistake_by_lvl,
aes(x=error, y=reorder(lvl, desc(-error))), group=stim_type) +
geom_col(aes(fill=stim_type)) +
theme(axis.text.y = element_text(angle=0),
axis.title.y = element_blank(),
panel.grid.major.x = element_line(size=0.5),
panel.grid.minor = element_line(size=0.02, colour = "#c0c0c0")) +
scale_x_continuous(labels=scales::percent) +
labs(caption="Fig.11. Error rates of category levels.", fill="Stimulus\nType") +
xlab("Percentage of mistakes over all participants")  +
facet_wrap(mistake_by_lvl$stim_type)
m_by_lvl_plot
mistake_by_stype <- exp_results %>%
mutate(accuracy=as.factor(accuracy))%>%
group_by(stim_type, accuracy) %>%
summarize(perc = round((n()/rows),2)*100)%>%
mutate(case=paste(stim_type,ifelse(accuracy==1,"positive","negative")))
m_by_stype_plot <- ggplot(mistake_by_stype,
aes(x="",y=perc, fill=case)) +
geom_bar(stat="identity", width=1, color="black") +
coord_polar("y", start=0) +
labs(caption="Fig.12. Error rates of stimulus types.", fill="Case")+
geom_text(aes(label = paste0(perc, "%")), position = position_stack(vjust=0.5)) +
labs(x = NULL, y = NULL, fill = NULL)+
theme(legend.position = "top")
m_by_stype_plot
aov_data <- exp_results %>%
group_by(branch, lvl, c_name, img, stimulus, stim_type) %>%
summarize(err=(1-mean(accuracy)))
aov_branch <- aov(err ~ branch, data=aov_data)
aov_lvl <- aov(err ~ lvl, data=aov_data)
aov_c_name <- aov(err ~ c_name, data=aov_data)
aov_img <- aov(err ~ img, data=aov_data)
aov_stim <- aov(err ~ stimulus, data=aov_data)
aov_stype <- aov(err ~ stim_type, data=aov_data)
summary.aov(aov_branch)
summary.aov(aov_lvl)
summary.aov(aov_c_name)
summary.aov(aov_img)
summary.aov(aov_stim)
summary.aov(aov_stype)
library(AICcmodavg)
candidates <- list(aov_branch,
aov_lvl,
aov_c_name,
aov_img,
aov_stim,
aov_stype)
nameset <- c("Branch", "Level", "Cat. Name", "Image", "Stimulus", "Stim. Type")
# AIC = 2K â€“ 2ln(L) (K= n# model parameter, L = likelihood)
aictab(candidates, nameset, sort=TRUE)
aov_lvl_type <- aov(err ~ lvl + stim_type, data=aov_data)
aov_lvl_branch <- aov(err ~ lvl + branch, data=aov_data)
aov_type_branch <- aov(err ~ stim_type + branch, data=aov_data)
aov_lvl_type_branch <- aov(err ~ lvl + stim_type + branch, data=aov_data)
summary.aov(aov_lvl_type)
summary.aov(aov_lvl_branch)
summary.aov(aov_type_branch)
summary.aov(aov_type_branch)
summary.aov(aov_lvl_type_branch)
candidates2 <- list(aov_lvl_type,
aov_lvl_branch,
aov_type_branch,
aov_lvl_type_branch)
nameset2 <- c("Level & Type", "Level & Branch", "Type & Branch", "Level & Type & Branch")
aictab(candidates2, nameset2, sort=TRUE)
tukey <- TukeyHSD(aov_lvl_branch)
print(tukey)
plot(tukey, sub="Fig.13. Tukey Confidence intervals for level and branch.")
rtOV <- exp_results %>%
group_by(stimulus, lvl, stim_type) %>%
summarize(rt_mean = mean(react_time))
rtOV_viz <- ggplot(rtOV, aes(x=rt_mean, fill=lvl))+
geom_histogram(bins = 15, position="dodge") +
ylab("Stimulus counts") +
xlab("Reaction Time (msec)")+
labs(caption="Fig.14. Distribution of stimuli frequencies.", fill="Category\nLevel")
rtOV_viz
rt_box <- ggplot(rtOV, aes(x=rt_mean, fill=lvl))+
geom_boxplot()+
facet_grid(rtOV$stim_type)+
theme(axis.text.y = element_blank(),
axis.ticks.y = element_blank(),
panel.grid.major.x = element_line(),
panel.grid.minor.x = element_line(color="#c0c0c0", size=0.5))+
scale_x_continuous(n.breaks = 14) +
labs(fill="",
caption="Fig.15 Boxplot representation of reaction time means \nover all stimuli") +
xlab("Reaction Time (msec)")
rt_box
library(reshape2)
rtable <- exp_results %>%
filter(index>100) %>%
filter(p_id != 1) %>%
group_by(lvl, stim_type) %>%
summarize(rt_mean = mean(react_time))
rmatrix <- matrix(c(1:6),nrow = 2, ncol=3,dimnames = list(c("F", "T"),c("Superordinate", "Basic Level", "Subordinate")))
for(i in 1:6){
lev <- rtable$lvl[i]
typ <- rtable$stim_type[i]
val <- rtable$rt_mean[i]
if (lev == "hypernym" & typ == TRUE){
rmatrix['T',"Superordinate"] <- val
} else if(lev == "hypernym" & typ == FALSE){
rmatrix['F',"Superordinate"] <- val
} else if(lev == "bl" & typ == TRUE){
rmatrix['T',"Basic Level"] <- val
} else if(lev == "bl" & typ == FALSE){
rmatrix['F',"Basic Level"] <- val
} else if(lev == "hyponym" & typ == TRUE){
rmatrix['T',"Subordinate"] <- val
} else if(lev == "hyponym" & typ == FALSE){
rmatrix['F',"Subordinate"] <- val
}
}
rt_data <- exp_results %>%
group_by(lvl, c_name, stim_type, branch, stimulus) %>%
summarise(rt_mean = mean(react_time)) %>%
mutate(c_name = as.factor(c_name))
r_true <- rt_data %>%
filter(stim_type == TRUE)
r_false <- rt_data %>%
filter(stim_type == FALSE)
roschAOV_true <- aov(rt_mean ~ lvl+c_name, data = r_true)
roschAOV_false <- aov(rt_mean ~ lvl+c_name, data = r_false)
tukey_r_true <- TukeyHSD(roschAOV_true, which = 'lvl')
tukey_r_false <- TukeyHSD(roschAOV_false, which = 'lvl')
summary.aov(roschAOV_true)
tukey_r_true
plot(tukey_r_true)
summary.aov(roschAOV_false)
tukey_r_false
plot(tukey_r_false)
df_for_rating <- exp_results %>%
filter(stim_type == TRUE) %>%
group_by(lvl, c_name, branch, img) %>%
summarise(rt_mean = mean(react_time), acc_mean = mean(accuracy)) %>%
mutate(lvl = ifelse(lvl=='hyponym', 'sub', ifelse(lvl=='hypernym', 'super', 'bl')))
all_img <- unique(df_for_rating$img)
df_rated_simple <- data.frame()
for (imag in all_img){
triple <- df_for_rating %>%
filter(img == imag)
blvl <- triple[which(triple$rt_mean == min(triple$rt_mean)),]
triple <- triple[which(triple$rt_mean != min(triple$rt_mean)),]
blvl$proj_lvl <- 'bl'
if(blvl$lvl == 'super'){
triple$proj_lvl <- 'sub'
df_rated_simple <- rbind(df_rated_simple, blvl)
df_rated_simple <- rbind(df_rated_simple, triple)
} else if(blvl$lvl == 'bl'){
sublvl <- triple[which(triple$lvl == "sub"),]
sublvl$proj_lvl <- "sub"
suplvl <- triple[which(triple$lvl == "super"),]
suplvl$proj_lvl <- "super"
df_rated_simple <- rbind(df_rated_simple, suplvl)
df_rated_simple <- rbind(df_rated_simple, blvl)
df_rated_simple <- rbind(df_rated_simple, sublvl)
} else{
triple$proj_lvl <- 'super'
df_rated_simple <- rbind(df_rated_simple, blvl)
df_rated_simple <- rbind(df_rated_simple, triple)
}
}
df_rated_simple$lvl <- as.factor(df_rated_simple$lvl)
df_rated_simple$proj_lvl <- as.factor(df_rated_simple$proj_lvl)
head(df_rated_simple[c("c_name", "lvl", "proj_lvl")], n = 9)
library(caret)
con_mat_bl <- confusionMatrix(data=df_rated_simple$proj_lvl, reference = df_rated_simple$lvl)
con_mat_bl
adv_rated_data = read_csv("../Past_experiments/Pilot2/computed_data/Gold_Standard_with_rt_and_blness.csv")
adv_rated_data <- adv_rated_data %>%
mutate(old_bl_label = old_bl_label == 1) %>%
mutate(blness_binary = floor(blness)==1)
summary(adv_rated_data[c('branch', 'synset', 'expert_certainty', 'old_bl_label', 'blness_binary', 'sample_median_rt', 'sample_mean_acc', 'sample_std_deviation')])
rt_acc <- exp_results %>%
filter(p_id != '1') %>%
mutate(type = ifelse(stim_type * accuracy == 1, 1,ifelse(stim_type & accuracy == 0, 3,ifelse(!stim_type & accuracy == 1, 2, 4)))) %>%
group_by(react_time, p_id, c_name, type) %>%
count() %>%
mutate(type = as.factor(type)) %>%
filter(c_name != 'furniture_n_01' & c_name != 'clothing_n_01' & c_name != 'edible_fruit_n_01' & c_name != 'musical_instrument_n_01' & c_name != 'hand_tool_n_01')
rated_df <- df_rated_simple[c('c_name', 'lvl')] %>%
filter(c_name != 'furniture_n_01' & c_name != 'clothing_n_01' & c_name != 'edible_fruit_n_01' & c_name != 'musical_instrument_n_01' & c_name != 'hand_tool_n_01')
rated_df_rts <- merge(rt_acc, rated_df, all.x=T)
effect_comparison <- ggplot(data=rated_df_rts,
mapping=aes(x=react_time, y=c_name), color=lvl)) +
rt_acc <- exp_results %>%
filter(p_id != '1') %>%
mutate(type = ifelse(stim_type * accuracy == 1, 1,ifelse(stim_type & accuracy == 0, 3,ifelse(!stim_type & accuracy == 1, 2, 4)))) %>%
group_by(react_time, p_id, c_name, type) %>%
count() %>%
mutate(type = as.factor(type)) %>%
filter(c_name != 'furniture_n_01' & c_name != 'clothing_n_01' & c_name != 'edible_fruit_n_01' & c_name != 'musical_instrument_n_01' & c_name != 'hand_tool_n_01')
rated_df <- df_rated_simple[c('c_name', 'lvl')] %>%
filter(c_name != 'furniture_n_01' & c_name != 'clothing_n_01' & c_name != 'edible_fruit_n_01' & c_name != 'musical_instrument_n_01' & c_name != 'hand_tool_n_01')
rated_df_rts <- merge(rt_acc, rated_df, all.x=T)
effect_comparison <- ggplot(data=rated_df_rts,
mapping=aes(x=react_time, y=c_name), color=lvl) +
geom_point() +
facet_wrap(rated_df_rts$type)+
coord_cartesian(xlim=c(400,1000))
effect_comparison
df_for_rating <- exp_results %>%
group_by(lvl, c_name, branch, img, stim_type, p_id) %>%
mutate(lvl = ifelse(lvl=='hyponym', 'sub', ifelse(lvl=='hypernym', 'super', 'bl')))
all_img <- unique(df_for_rating$img)
df_rated_simpleplus <- data.frame()
df_for_rating <- exp_results %>%
group_by(lvl, c_name, branch, img, stim_type, p_id) %>%
mutate(lvl = ifelse(lvl=='hyponym', 'sub', ifelse(lvl=='hypernym', 'super', 'bl')))
all_img <- unique(df_for_rating$img)
df_rated_simpleplus <- data.frame()
triple <- df_for_rating %>%
filter(img == imag)
is_bl_to_participant = c()
for(i in 1:p_num){
bl <- triple[which(triple$rt_mean == min(triple$rt_mean)),]
is_bl_to_participant <- append(is_bl_to_participant, bl)
}
bl_tally <- is_bl_to_participant %>%
tally()
bl_tally <- data.frame(is_bl_to_participant) %>%
tally()
View(bl_tally)
View(bl_tally)
View(is_bl_to_participant)
View(is_bl_to_participant)
is_bl_to_participant = data.frame()
for(i in 1:p_num){
bl <- triple[which(triple$rt_mean == min(triple$rt_mean)),]
is_bl_to_participant <- rbind(is_bl_to_participant, bl)
}
bl_tally <- data.frame(is_bl_to_participant) %>%
tally()
View(is_bl_to_participant)
View(is_bl_to_participant)
bl <- triple[which(triple$react_time == min(triple$react_time)),]
for(i in 1:p_num){
bl <- triple[which(triple$react_time == min(triple$react_time)),]
is_bl_to_participant <- rbind(is_bl_to_participant, bl)
}
bl_tally <- data.frame(is_bl_to_participant) %>%
tally()
View(bl_tally)
View(bl_tally)
bl_tally <- data.frame(is_bl_to_participant) %>%
group_by('c_name')
bl_tally <- data.frame(is_bl_to_participant) %>%
group_by('c_name')%>%
tally()
bl_tally <- data.frame(is_bl_to_participant) %>%
group_by(c_name)%>%
tally()
